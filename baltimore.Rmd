---
title: "Traffic Stops by the Baltimore Police"
author: "Lindsay Huth"
date: "12/10/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library('knitr')
```

## Digging into the data

I'm part of a team project that's been investigating the Baltimore police department this fall. I'm the sole data journalist, so I got a head start over the summer requesting traffic stop records from the Governor's Office of Crime Control and Prevention, which receives and analyzes the records from departments across Maryland.

I planned to use the records to determine whether the Baltimore police stop and search minorities disproportionately to the city's population, and to compare Baltimore's patterns to other departments statewide.

For each traffic stop reported by a law enforcement agency, we have fields like the driver's race and age, the stop reason, whether the officer conducted a search and whether the search turned up anything (contraband, property or both). Check out a snippet of Baltimore's stops from 2011:

```{r echo = FALSE, results = 'asis'}
load(file="port_balt2011.RData")
kable(port_balt2011)
```

But when I pulled the Baltimore data and began working through data quality checks, the patterns...didn't make sense. 

Check out the number of stops reported by the Baltimore police each year (two years are missing because the law mandating data collection sunsetted during those years):

```{r echo = FALSE}
load(file="port_baltStops.RData")
barplot(port_baltstops$V1, main="Stops Reported by Baltimore City Police", names.arg=c("2009", "2011", "2012", "2013", "2015"), ylab="Stops")
```

The data show just 4,410 stops in 2009 -- and over 80,000 in 2013. I also calculated at the search rate (percent of stopped drivers that officers search) and the hit rate (the percent of searches that are 'successful,' turning up contraband, property or both) for each year. Both were erratic, too. Here's a look at the hit rate:

```{r echo = FALSE}
load(file="port_baltsearches.RData")
barplot(port_baltsearches$V1, main="Hit Rates for Baltimore City Police's Traffic Stops", names.arg=c("2009", "2011", "2012", "2013", "2015"), ylab="Hit Rate (Percent)")
```

The department reported just 36 searches in 2009, and zero hits.

I immediately began talking to sources: the data analyst at the Governor's Office, the data and compliance officials at the Baltimore police department, researchers who helped set up the data collection system and the state delegates who sponsored the bill that mandates this data be collected.

No one could explain the patterns I was seeing. But no one thought they represented actual policing practices. The problem, it became apparent, was the data collection.

For contrast, I pulled data from the region one source pointed to as the model for high-tech, data-driven policing: Los Angeles. The California data was available from the Stanford Open Policing Project, and I parsed out the stops from the county (individual departments weren't given). Unlike Baltimore, the stop numbers and search rates are remarkably consistent:

```{r echo = FALSE}
load(file="port_lastops.RData")
barplot(lastops$Freq, main="Stops Reported in Los Angeles County",names.arg=lastops$Var1, ylim=c(0, 1000000), ylab="Stops")
```

```{r lasearch}
load(file="port_lahit.RData")
barplot(lahit$HitRate, main="Hit Rates Reported for Los Angeles County Traffic Stops",names.arg=lahit$Year, ylim=c(0,10), ylab="Hit Rate (Percent)")
```

I learned that Baltimore's technology lags behind the rest of the state: rather than reporting their stops electronically through computers in its cars, Baltimore officers fill out paper reports, which are manually entered into computers by other officers too injured for patrolling, sometimes month laters.

The Baltimore police are under consent decree, and the last year's Department of Justice investigation found that large numbers of stops and searches were absent from police records. When officers did report stops, “they do not consistently record important information connected to it,” the Justice Department report noted.

I wondered if this was a Baltimore-specific problem. I pulled data from other departments, large and small, across Maryland. But instead of seeing order, like the LA stops, each Maryland department had its own confusing pattern of stops, searches and hits. Here are stop numbers from a sampling of departments:

```{r echo=FALSE}
load("port_mocostops.RData")
barplot(port_mocostops$V1, main="Stops Reported by Montgomery County Police", ylab="Stops", names.arg=c("2009", "2011", "2012", "2013", "2015"))
```

```{r echo=FALSE}
load("port_bcstops.RData")
barplot(port_bcstops$V1, main="Stops Reported by Baltimore County Police", ylab="Stops", names.arg=c("2009", "2011", "2012", "2013", "2015"),ylim=c(0, 125000))
```

```{r nc}
load("port_ncstops.RData")
barplot(port_ncstops$V1, main="Stops Reported by New Carrollton Police", ylab="Stops", names.arg=c("2009", "2011", "2012", "2013", "2015"))
```

I have talked to officials from these departments, and they have said the data don't make sense and don't seem reliable -- but they're not sure why. All of my sources have told me -- and my independent analysis has confirmed -- that the huge, unexplained changes in stops, searches and hits indicate the data is incomplete and unreliable for analysis.

That's a problem. All departments are required to report this data to enable the state to pinpoint which departments engage in racial profiling. The original law, passed 16 years ago, came out of a settlement between the Maryland State Police and Robert Wilkins, a black attorney who sued the department for stopping him because of his race. The law is supposed to have a chilling effect on racial profiling, but with incomplete data, it doesn't.

My story on this issue is nearly complete and will be published by the end of December. Stay tuned.


##

